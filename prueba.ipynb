{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fd9651-08ad-4d71-b8a0-51ce3ac5e392",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jupyter/storage2/working_area_silvana2/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55c0489b-059e-4dfa-b9e8-8d3da7fd7597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Nov_18_09:45:30_PST_2021\n",
      "Cuda compilation tools, release 11.5, V11.5.119\n",
      "Build cuda_11.5.r11.5/compiler.30672275_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0108842-1884-4278-8252-e4ac636b413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "2.0.2+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83e4d026-4885-43c3-83ca-6f979a1298cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import k2\n",
    "import lhotse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b26788f-98cc-4c1f-a366-b3746d88ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/jupyter/storage2/working_area_silvana2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d4f885-ad9b-4cbe-bde6-e32ae00419dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/k2-fsa/icefall\n",
      "  Cloning https://github.com/k2-fsa/icefall to /tmp/pip-req-build-x1hzv2yk\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/k2-fsa/icefall /tmp/pip-req-build-x1hzv2yk\n",
      "  Resolved https://github.com/k2-fsa/icefall to commit 9e9fe7954d13c5ee8f10e990b358cf8c752a24e6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: kaldilm in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (1.15.1)\n",
      "Requirement already satisfied: kaldifst in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (1.7.8)\n",
      "Requirement already satisfied: typeguard in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (4.1.5)\n",
      "Requirement already satisfied: tensorboard in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (2.15.1)\n",
      "Requirement already satisfied: kaldi-decoder in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (0.2.3)\n",
      "Requirement already satisfied: onnxruntime==1.16.3 in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (1.16.3)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (0.1.99)\n",
      "Requirement already satisfied: kaldialign in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (0.7.2)\n",
      "Requirement already satisfied: num2words in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (0.5.13)\n",
      "Requirement already satisfied: onnx==1.15.0 in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (1.15.0)\n",
      "Requirement already satisfied: black==22.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (22.3.0)\n",
      "Requirement already satisfied: dill in /home/jupyter/.local/lib/python3.10/site-packages (from icefall==1.0) (0.3.7)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/lib/python3/dist-packages (from black==22.3.0->icefall==1.0) (2.5.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from black==22.3.0->icefall==1.0) (8.0.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/jupyter/.local/lib/python3.10/site-packages (from black==22.3.0->icefall==1.0) (0.11.2)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from black==22.3.0->icefall==1.0) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (from black==22.3.0->icefall==1.0) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /home/jupyter/.local/lib/python3.10/site-packages (from onnx==1.15.0->icefall==1.0) (4.23.4)\n",
      "Requirement already satisfied: numpy in /home/jupyter/.local/lib/python3.10/site-packages (from onnx==1.15.0->icefall==1.0) (1.26.2)\n",
      "Requirement already satisfied: coloredlogs in /home/jupyter/.local/lib/python3.10/site-packages (from onnxruntime==1.16.3->icefall==1.0) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/jupyter/.local/lib/python3.10/site-packages (from onnxruntime==1.16.3->icefall==1.0) (1.12)\n",
      "Requirement already satisfied: packaging in /home/jupyter/.local/lib/python3.10/site-packages (from onnxruntime==1.16.3->icefall==1.0) (23.2)\n",
      "Requirement already satisfied: flatbuffers in /home/jupyter/.local/lib/python3.10/site-packages (from onnxruntime==1.16.3->icefall==1.0) (23.5.26)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/jupyter/.local/lib/python3.10/site-packages (from num2words->icefall==1.0) (0.6.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (2.24.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (2.31.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard->icefall==1.0) (1.16.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (3.5.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (3.0.1)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (1.59.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (0.7.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (2.0.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard->icefall==1.0) (59.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->icefall==1.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from typeguard->icefall==1.0) (4.8.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->icefall==1.0) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->icefall==1.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard->icefall==1.0) (0.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->icefall==1.0) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->icefall==1.0) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyter/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->icefall==1.0) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->icefall==1.0) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->icefall==1.0) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jupyter/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->icefall==1.0) (2.1.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jupyter/.local/lib/python3.10/site-packages (from coloredlogs->onnxruntime==1.16.3->icefall==1.0) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/jupyter/.local/lib/python3.10/site-packages (from sympy->onnxruntime==1.16.3->icefall==1.0) (1.3.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->icefall==1.0) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard->icefall==1.0) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/k2-fsa/icefall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a5a34a-f641-44af-a541-545876d0d7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kaldifst in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 1)) (1.7.8)\n",
      "Requirement already satisfied: kaldilm in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 2)) (1.15.1)\n",
      "Requirement already satisfied: kaldialign in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 3)) (0.7.2)\n",
      "Requirement already satisfied: num2words in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 4)) (0.5.13)\n",
      "Requirement already satisfied: kaldi-decoder in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 5)) (0.2.3)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 6)) (0.1.99)\n",
      "Requirement already satisfied: tensorboard in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (2.15.1)\n",
      "Requirement already satisfied: typeguard in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 8)) (4.1.5)\n",
      "Requirement already satisfied: dill in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 9)) (0.3.7)\n",
      "Requirement already satisfied: black==22.3.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 10)) (22.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (from black==22.3.0->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 10)) (1.0.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/lib/python3/dist-packages (from black==22.3.0->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 10)) (2.5.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/lib/python3/dist-packages (from black==22.3.0->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 10)) (8.0.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/jupyter/.local/lib/python3.10/site-packages (from black==22.3.0->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 10)) (0.11.2)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from black==22.3.0->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 10)) (2.0.1)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /home/jupyter/.local/lib/python3.10/site-packages (from num2words->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (59.6.0)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (1.16.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (1.26.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (4.23.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (0.7.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (2.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (3.5.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (2.31.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (1.59.3)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from typeguard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 8)) (4.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (0.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyter/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (3.3.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jupyter/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (2.1.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard->-r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt (line 7)) (0.4.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sphinx_rtd_theme in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: sphinx in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (7.2.6)\n",
      "Requirement already satisfied: sphinxcontrib-youtube==1.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from -r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: docutils<0.21 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx_rtd_theme->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 1)) (0.20.1)\n",
      "Requirement already satisfied: sphinxcontrib-jquery<5,>=4 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx_rtd_theme->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 1)) (4.1)\n",
      "Requirement already satisfied: babel>=2.9 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (2.13.1)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.1.9)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.0.6)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (0.7.13)\n",
      "Requirement already satisfied: Pygments>=2.14 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (2.17.2)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: packaging>=21.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (23.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /usr/lib/python3/dist-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.0.7)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: imagesize>=1.3 in /home/jupyter/.local/lib/python3.10/site-packages (from sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.25.0->sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests>=2.25.0->sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.25.0->sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyter/.local/lib/python3.10/site-packages (from requests>=2.25.0->sphinx->-r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt (line 2)) (3.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /home/jupyter/storage2/working_area_silvana2/icefall/requirements.txt\n",
    "!pip install -r /home/jupyter/storage2/working_area_silvana2/icefall/docs/requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "584bec40-8bda-4cae-b812-904c379584c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=/home/jupyter/storage2/working_area_silvana2/icefall:$PYTHONPATH\n",
    "!export PATH=$PATH:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd09a3f2-a18e-47fc-a7dc-c66175686f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x /home/jupyter/storage2/working_area_silvana2/icefall/egs/librispeech/ASR/shared/parse_options.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16637886-0fc6-4024-9dfa-6a0744f3f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-12 20:06:45 (prepare.sh:63:main) dl_dir: /home/jupyter/storage2/working_area_silvana2/icefall/egs/librispeech/ASR/download\n",
      "2023-12-12 20:06:45 (prepare.sh:66:main) Stage -1: Download LM\n",
      "2023-12-12 20:06:45 (prepare.sh:75:main) Stage 0: Download data\n",
      "2023-12-12 20:06:45 (prepare.sh:97:main) Stage 1: Prepare LibriSpeech manifest\n",
      "2023-12-12 20:06:45 (prepare.sh:108:main) Stage 2: Prepare musan manifest\n",
      "2023-12-12 20:06:45 (prepare.sh:119:main) Stage 3: Compute fbank for librispeech\n",
      "2023-12-12 20:06:45 (prepare.sh:153:main) Stage 4: Compute fbank for musan\n",
      "2023-12-12 20:06:45 (prepare.sh:162:main) Stage 5: Prepare phone based lang\n",
      "2023-12-12 20:06:45 (prepare.sh:170:main) Stage 6: Prepare BPE based lang\n",
      "2023-12-12 20:06:45 (prepare.sh:226:main) Stage 7: Prepare bigram token-level P for MMI training\n",
      "2023-12-12 20:06:45 (prepare.sh:257:main) Stage 8: Prepare G\n",
      "2023-12-12 20:06:48.647229: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-12 20:06:48.775465: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-12 20:06:49.321312: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 20:06:49.321412: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 20:06:49.452932: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 20:06:49.744524: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 20:06:51.634940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-12 20:06:55,596 INFO [prepare_lang_fst.py:174] Building standard CTC topology\n",
      "2023-12-12 20:06:57,625 INFO [prepare_lang_fst.py:183] Building L\n",
      "2023-12-12 20:07:03,803 INFO [prepare_lang_fst.py:191] Building HL\n",
      "2023-12-12 20:07:57,090 INFO [prepare_lang_fst.py:204] Building HLG\n",
      "2023-12-12 20:10:41 (prepare.sh:292:main) Stage 9: Compile HLG\n",
      "2023-12-12 20:10:43.175576: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-12 20:10:43.178943: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-12 20:10:43.223348: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-12 20:10:43.223393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-12 20:10:43.224915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-12 20:10:43.232527: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-12 20:10:44.218409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-12 20:10:45,377 INFO [compile_hlg.py:155] Processing data/lang_phone\n",
      "2023-12-12 20:10:45,636 INFO [lexicon.py:171] Converting L.pt to Linv.pt\n",
      "2023-12-12 20:10:46,075 INFO [compile_hlg.py:73] Building ctc_topo. max_token_id: 71\n",
      "2023-12-12 20:10:46,232 INFO [compile_hlg.py:82] Loading G_3_gram.fst.txt\n",
      "2023-12-12 20:10:53,023 INFO [compile_hlg.py:93] Intersecting L and G\n",
      "2023-12-12 20:11:20,307 INFO [compile_hlg.py:95] LG shape: (19672550, None)\n",
      "2023-12-12 20:11:20,307 INFO [compile_hlg.py:97] Connecting LG\n",
      "2023-12-12 20:11:20,308 INFO [compile_hlg.py:99] LG shape after k2.connect: (19672550, None)\n",
      "2023-12-12 20:11:20,308 INFO [compile_hlg.py:101] <class 'torch.Tensor'>\n",
      "2023-12-12 20:11:20,308 INFO [compile_hlg.py:102] Determinizing LG\n",
      "2023-12-12 20:12:13,138 INFO [compile_hlg.py:105] <class '_k2.ragged.RaggedTensor'>\n",
      "2023-12-12 20:12:13,139 INFO [compile_hlg.py:107] Connecting LG after k2.determinize\n",
      "2023-12-12 20:12:13,139 INFO [compile_hlg.py:110] Removing disambiguation symbols on LG\n",
      "2023-12-12 20:12:48,181 INFO [compile_hlg.py:122] LG shape after k2.remove_epsilon: (15949565, None)\n",
      "2023-12-12 20:12:59,020 INFO [compile_hlg.py:127] Arc sorting LG\n",
      "2023-12-12 20:12:59,020 INFO [compile_hlg.py:130] Composing H and LG\n"
     ]
    }
   ],
   "source": [
    "!cd /home/jupyter/storage2/working_area_silvana2/icefall/egs/librispeech/ASR && ./prepare.sh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed705667-b07d-4494-b76d-49e6b5ebb0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/jupyter/.local/lib/python3.10/site-packages (2.15.0.post1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (2.15.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: packaging in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (1.26.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (4.23.4)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jupyter/.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/jupyter/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyter/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jupyter/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9a89532-6be7-4fea-846a-919a29663994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 13 17:36:36 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   32C    P0    26W /  70W |      2MiB / 15360MiB |      7%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96643c85-3aca-4aa0-8544-ea5d6c35d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:36:46.309733: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 17:36:46.313206: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 17:36:46.358189: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 17:36:46.358243: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 17:36:46.359767: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 17:36:46.367431: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 17:36:47.266561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "usage: train.py [-h] [--world-size WORLD_SIZE] [--master-port MASTER_PORT]\n",
      "                [--tensorboard TENSORBOARD] [--num-epochs NUM_EPOCHS]\n",
      "                [--start-epoch START_EPOCH] [--start-batch START_BATCH]\n",
      "                [--exp-dir EXP_DIR] [--bpe-model BPE_MODEL]\n",
      "                [--initial-lr INITIAL_LR] [--lr-batches LR_BATCHES]\n",
      "                [--lr-epochs LR_EPOCHS] [--context-size CONTEXT_SIZE]\n",
      "                [--prune-range PRUNE_RANGE] [--lm-scale LM_SCALE]\n",
      "                [--am-scale AM_SCALE] [--simple-loss-scale SIMPLE_LOSS_SCALE]\n",
      "                [--seed SEED] [--print-diagnostics PRINT_DIAGNOSTICS]\n",
      "                [--save-every-n SAVE_EVERY_N] [--keep-last-k KEEP_LAST_K]\n",
      "                [--average-period AVERAGE_PERIOD] [--use-fp16 USE_FP16]\n",
      "                [--delay-penalty DELAY_PENALTY]\n",
      "                [--dynamic-chunk-training DYNAMIC_CHUNK_TRAINING]\n",
      "                [--causal-convolution CAUSAL_CONVOLUTION]\n",
      "                [--short-chunk-size SHORT_CHUNK_SIZE]\n",
      "                [--num-left-chunks NUM_LEFT_CHUNKS] [--full-libri FULL_LIBRI]\n",
      "                [--mini-libri MINI_LIBRI] [--manifest-dir MANIFEST_DIR]\n",
      "                [--max-duration MAX_DURATION]\n",
      "                [--bucketing-sampler BUCKETING_SAMPLER]\n",
      "                [--num-buckets NUM_BUCKETS]\n",
      "                [--concatenate-cuts CONCATENATE_CUTS]\n",
      "                [--duration-factor DURATION_FACTOR] [--gap GAP]\n",
      "                [--on-the-fly-feats ON_THE_FLY_FEATS] [--shuffle SHUFFLE]\n",
      "                [--drop-last DROP_LAST] [--return-cuts RETURN_CUTS]\n",
      "                [--num-workers NUM_WORKERS]\n",
      "                [--enable-spec-aug ENABLE_SPEC_AUG]\n",
      "                [--spec-aug-time-warp-factor SPEC_AUG_TIME_WARP_FACTOR]\n",
      "                [--enable-musan ENABLE_MUSAN]\n",
      "                [--input-strategy INPUT_STRATEGY]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --world-size WORLD_SIZE\n",
      "                        Number of GPUs for DDP training. (default: 1)\n",
      "  --master-port MASTER_PORT\n",
      "                        Master port to use for DDP training. (default: 12354)\n",
      "  --tensorboard TENSORBOARD\n",
      "                        Should various information be logged in tensorboard.\n",
      "                        (default: True)\n",
      "  --num-epochs NUM_EPOCHS\n",
      "                        Number of epochs to train. (default: 30)\n",
      "  --start-epoch START_EPOCH\n",
      "                        Resume training from this epoch. It should be\n",
      "                        positive. If larger than 1, it will load checkpoint\n",
      "                        from exp-dir/epoch-{start_epoch-1}.pt (default: 1)\n",
      "  --start-batch START_BATCH\n",
      "                        If positive, --start-epoch is ignored and it loads the\n",
      "                        checkpoint from exp-dir/checkpoint-{start_batch}.pt\n",
      "                        (default: 0)\n",
      "  --exp-dir EXP_DIR     The experiment dir. It specifies the directory where\n",
      "                        all training related files, e.g., checkpoints, log,\n",
      "                        etc, are saved (default:\n",
      "                        pruned_transducer_stateless4/exp)\n",
      "  --bpe-model BPE_MODEL\n",
      "                        Path to the BPE model (default:\n",
      "                        data/lang_bpe_500/bpe.model)\n",
      "  --initial-lr INITIAL_LR\n",
      "                        The initial learning rate. This value should not need\n",
      "                        to be changed. (default: 0.003)\n",
      "  --lr-batches LR_BATCHES\n",
      "                        Number of steps that affects how rapidly the learning\n",
      "                        rate decreases. We suggest not to change this.\n",
      "                        (default: 5000)\n",
      "  --lr-epochs LR_EPOCHS\n",
      "                        Number of epochs that affects how rapidly the learning\n",
      "                        rate decreases. (default: 6)\n",
      "  --context-size CONTEXT_SIZE\n",
      "                        The context size in the decoder. 1 means bigram; 2\n",
      "                        means tri-gram (default: 2)\n",
      "  --prune-range PRUNE_RANGE\n",
      "                        The prune range for rnnt loss, it means how many\n",
      "                        symbols(context)we are using to compute the loss\n",
      "                        (default: 5)\n",
      "  --lm-scale LM_SCALE   The scale to smooth the loss with lm (output of\n",
      "                        prediction network) part. (default: 0.25)\n",
      "  --am-scale AM_SCALE   The scale to smooth the loss with am (output of\n",
      "                        encoder network) part. (default: 0.0)\n",
      "  --simple-loss-scale SIMPLE_LOSS_SCALE\n",
      "                        To get pruning ranges, we will calculate a simple\n",
      "                        versionloss(joiner is just addition), this simple loss\n",
      "                        also uses fortraining (as a regularization item). We\n",
      "                        will scale the simple losswith this parameter before\n",
      "                        adding to the final loss. (default: 0.5)\n",
      "  --seed SEED           The seed for random generators intended for\n",
      "                        reproducibility (default: 42)\n",
      "  --print-diagnostics PRINT_DIAGNOSTICS\n",
      "                        Accumulate stats on activations, print them and exit.\n",
      "                        (default: False)\n",
      "  --save-every-n SAVE_EVERY_N\n",
      "                        Save checkpoint after processing this number of\n",
      "                        batches\" periodically. We save checkpoint to exp-dir/\n",
      "                        whenever params.batch_idx_train {'option_strings': ['\n",
      "                        --save-every-n'], 'dest': 'save_every_n', 'nargs':\n",
      "                        None, 'const': None, 'default': 8000, 'type': 'int',\n",
      "                        'choices': None, 'required': False, 'help': 'Save\n",
      "                        checkpoint after processing this number of batches\"\\n\n",
      "                        periodically. We save checkpoint to exp-dir/\n",
      "                        whenever\\n params.batch_idx_train % save_every_n == 0.\n",
      "                        The checkpoint filename\\n has the form: f\\'exp-\n",
      "                        dir/checkpoint-{params.batch_idx_train}.pt\\'\\n Note:\n",
      "                        It also saves checkpoint to `exp-dir/epoch-xxx.pt` at\n",
      "                        the\\n end of each epoch where `xxx` is the epoch\n",
      "                        number counting from 1.\\n ', 'metavar': None,\n",
      "                        'container': <argparse._ArgumentGroup object at\n",
      "                        0x7f0c8c09f700>, 'prog': 'train.py'}ave_every_n == 0.\n",
      "                        The checkpoint filename has the form: f'exp-\n",
      "                        dir/checkpoint-{params.batch_idx_train}.pt' Note: It\n",
      "                        also saves checkpoint to `exp-dir/epoch-xxx.pt` at the\n",
      "                        end of each epoch where `xxx` is the epoch number\n",
      "                        counting from 1. (default: 8000)\n",
      "  --keep-last-k KEEP_LAST_K\n",
      "                        Only keep this number of checkpoints on disk. For\n",
      "                        instance, if it is 3, there are only 3 checkpoints in\n",
      "                        the exp-dir with filenames `checkpoint-xxx.pt`. It\n",
      "                        does not affect checkpoints with name `epoch-xxx.pt`.\n",
      "                        (default: 20)\n",
      "  --average-period AVERAGE_PERIOD\n",
      "                        Update the averaged model, namely `model_avg`, after\n",
      "                        processing this number of batches. `model_avg` is a\n",
      "                        separate version of model, in which each floating-\n",
      "                        point parameter is the average of all the parameters\n",
      "                        from the start of training. Each time we take the\n",
      "                        average, we do: `model_avg = model * (average_period /\n",
      "                        batch_idx_train) + model_avg * ((batch_idx_train -\n",
      "                        average_period) / batch_idx_train)`. (default: 100)\n",
      "  --use-fp16 USE_FP16   Whether to use half precision training. (default:\n",
      "                        False)\n",
      "  --delay-penalty DELAY_PENALTY\n",
      "                        A constant value used to penalize symbol delay, to\n",
      "                        encourage streaming models to emit symbols earlier.\n",
      "                        See https://github.com/k2-fsa/k2/issues/955 and\n",
      "                        https://arxiv.org/pdf/2211.00490.pdf for more details.\n",
      "                        (default: 0.0)\n",
      "  --dynamic-chunk-training DYNAMIC_CHUNK_TRAINING\n",
      "                        Whether to use dynamic_chunk_training, if you want a\n",
      "                        streaming model, this requires to be True. (default:\n",
      "                        False)\n",
      "  --causal-convolution CAUSAL_CONVOLUTION\n",
      "                        Whether to use causal convolution, this requires to be\n",
      "                        True when using dynamic_chunk_training. (default:\n",
      "                        False)\n",
      "  --short-chunk-size SHORT_CHUNK_SIZE\n",
      "                        Chunk length of dynamic training, the chunk size would\n",
      "                        be either max sequence length of current batch or\n",
      "                        uniformly sampled from (1, short_chunk_size).\n",
      "                        (default: 25)\n",
      "  --num-left-chunks NUM_LEFT_CHUNKS\n",
      "                        How many left context can be seen in chunks when\n",
      "                        calculating attention. (default: 4)\n",
      "\n",
      "ASR data related options:\n",
      "  These options are used for the preparation of PyTorch DataLoaders from\n",
      "  Lhotse CutSet's -- they control the effective batch sizes, sampling\n",
      "  strategies, applied data augmentations, etc.\n",
      "\n",
      "  --full-libri FULL_LIBRI\n",
      "                        Used only when --mini-libri is False.When enabled, use\n",
      "                        960h LibriSpeech. Otherwise, use 100h subset.\n",
      "                        (default: True)\n",
      "  --mini-libri MINI_LIBRI\n",
      "                        True for mini librispeech (default: False)\n",
      "  --manifest-dir MANIFEST_DIR\n",
      "                        Path to directory with train/valid/test cuts.\n",
      "                        (default: data/fbank)\n",
      "  --max-duration MAX_DURATION\n",
      "                        Maximum pooled recordings duration (seconds) in a\n",
      "                        single batch. You can reduce it if it causes CUDA OOM.\n",
      "                        (default: 200.0)\n",
      "  --bucketing-sampler BUCKETING_SAMPLER\n",
      "                        When enabled, the batches will come from buckets of\n",
      "                        similar duration (saves padding frames). (default:\n",
      "                        True)\n",
      "  --num-buckets NUM_BUCKETS\n",
      "                        The number of buckets for the\n",
      "                        DynamicBucketingSampler(you might want to increase it\n",
      "                        for larger datasets). (default: 30)\n",
      "  --concatenate-cuts CONCATENATE_CUTS\n",
      "                        When enabled, utterances (cuts) will be concatenated\n",
      "                        to minimize the amount of padding. (default: False)\n",
      "  --duration-factor DURATION_FACTOR\n",
      "                        Determines the maximum duration of a concatenated cut\n",
      "                        relative to the duration of the longest cut in a\n",
      "                        batch. (default: 1.0)\n",
      "  --gap GAP             The amount of padding (in seconds) inserted between\n",
      "                        concatenated cuts. This padding is filled with noise\n",
      "                        when noise augmentation is used. (default: 1.0)\n",
      "  --on-the-fly-feats ON_THE_FLY_FEATS\n",
      "                        When enabled, use on-the-fly cut mixing and feature\n",
      "                        extraction. Will drop existing precomputed feature\n",
      "                        manifests if available. (default: False)\n",
      "  --shuffle SHUFFLE     When enabled (=default), the examples will be shuffled\n",
      "                        for each epoch. (default: True)\n",
      "  --drop-last DROP_LAST\n",
      "                        Whether to drop last batch. Used by sampler. (default:\n",
      "                        True)\n",
      "  --return-cuts RETURN_CUTS\n",
      "                        When enabled, each batch will have the field:\n",
      "                        batch['supervisions']['cut'] with the cuts that were\n",
      "                        used to construct it. (default: True)\n",
      "  --num-workers NUM_WORKERS\n",
      "                        The number of training dataloader workers that collect\n",
      "                        the batches. (default: 2)\n",
      "  --enable-spec-aug ENABLE_SPEC_AUG\n",
      "                        When enabled, use SpecAugment for training dataset.\n",
      "                        (default: True)\n",
      "  --spec-aug-time-warp-factor SPEC_AUG_TIME_WARP_FACTOR\n",
      "                        Used only when --enable-spec-aug is True. It specifies\n",
      "                        the factor for time warping in SpecAugment. Larger\n",
      "                        values mean more warping. A value less than 1 means to\n",
      "                        disable time warp. (default: 80)\n",
      "  --enable-musan ENABLE_MUSAN\n",
      "                        When enabled, select noise from MUSAN and mix itwith\n",
      "                        training dataset. (default: True)\n",
      "  --input-strategy INPUT_STRATEGY\n",
      "                        AudioSamples or PrecomputedFeatures (default:\n",
      "                        PrecomputedFeatures)\n"
     ]
    }
   ],
   "source": [
    "!cd /home/jupyter/storage2/working_area_silvana2/icefall/egs/librispeech/ASR &&./pruned_transducer_stateless4/train.py --help\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df92c09-a6da-4906-bc35-710bc54a9bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-13 17:37:56.770777: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-13 17:37:56.774212: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-13 17:37:56.819571: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 17:37:56.819678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 17:37:56.821197: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 17:37:56.828838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 17:37:57.725470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-13 17:38:01,001 INFO [train.py:912] Training started\n",
      "2023-12-13 17:38:01,003 INFO [train.py:922] Device: cuda:0\n",
      "2023-12-13 17:38:01,005 INFO [train.py:936] {'frame_shift_ms': 10.0, 'best_train_loss': inf, 'best_valid_loss': inf, 'best_train_epoch': -1, 'best_valid_epoch': -1, 'batch_idx_train': 0, 'log_interval': 50, 'reset_interval': 200, 'valid_interval': 3000, 'feature_dim': 80, 'subsampling_factor': 4, 'encoder_dim': 512, 'nhead': 8, 'dim_feedforward': 2048, 'num_encoder_layers': 12, 'decoder_dim': 512, 'joiner_dim': 512, 'model_warm_step': 3000, 'env_info': {'k2-version': '1.24.3', 'k2-build-type': 'Release', 'k2-with-cuda': True, 'k2-git-sha1': 'e400fa3b456faf8afe0ee5bfe572946b4921a3db', 'k2-git-date': 'Sat Jul 15 04:21:50 2023', 'lhotse-version': '1.17.0.dev+git.b869488.clean', 'torch-version': '2.0.1+cu117', 'torch-cuda-available': True, 'torch-cuda-version': '11.7', 'python-version': '3.1', 'icefall-git-branch': 'master', 'icefall-git-sha1': 'f08af2f-clean', 'icefall-git-date': 'Mon Dec 4 14:29:42 2023', 'icefall-path': '/home/jupyter/.local/lib/python3.10/site-packages', 'k2-path': '/home/jupyter/.local/lib/python3.10/site-packages/k2/__init__.py', 'lhotse-path': '/home/jupyter/.local/lib/python3.10/site-packages/lhotse/__init__.py', 'hostname': 'ip-172-31-36-4', 'IP address': '172.31.36.4'}, 'world_size': 1, 'master_port': 12354, 'tensorboard': True, 'num_epochs': 9, 'start_epoch': 1, 'start_batch': 0, 'exp_dir': PosixPath('pruned_transducer_stateless4/exp'), 'bpe_model': 'data/lang_bpe_500/bpe.model', 'initial_lr': 0.003, 'lr_batches': 5000, 'lr_epochs': 6, 'context_size': 2, 'prune_range': 5, 'lm_scale': 0.25, 'am_scale': 0.0, 'simple_loss_scale': 0.5, 'seed': 42, 'print_diagnostics': False, 'save_every_n': 8000, 'keep_last_k': 20, 'average_period': 100, 'use_fp16': False, 'delay_penalty': 0.0, 'dynamic_chunk_training': False, 'causal_convolution': False, 'short_chunk_size': 25, 'num_left_chunks': 4, 'full_libri': True, 'mini_libri': False, 'manifest_dir': PosixPath('data/fbank'), 'max_duration': 50, 'bucketing_sampler': True, 'num_buckets': 30, 'concatenate_cuts': False, 'duration_factor': 1.0, 'gap': 1.0, 'on_the_fly_feats': False, 'shuffle': True, 'drop_last': True, 'return_cuts': True, 'num_workers': 2, 'enable_spec_aug': True, 'spec_aug_time_warp_factor': 80, 'enable_musan': True, 'input_strategy': 'PrecomputedFeatures', 'blank_id': 0, 'vocab_size': 500}\n",
      "2023-12-13 17:38:01,005 INFO [train.py:938] About to create model\n",
      "2023-12-13 17:38:01,429 INFO [train.py:942] Number of model parameters: 78648040\n",
      "2023-12-13 17:38:05,039 INFO [asr_datamodule.py:434] About to get the shuffled train-clean-100,             train-clean-360 and train-other-500 cuts\n",
      "2023-12-13 17:38:05,040 INFO [asr_datamodule.py:232] Enable MUSAN\n",
      "2023-12-13 17:38:05,040 INFO [asr_datamodule.py:233] About to get Musan cuts\n",
      "2023-12-13 17:38:07,288 INFO [asr_datamodule.py:257] Enable SpecAugment\n",
      "2023-12-13 17:38:07,288 INFO [asr_datamodule.py:258] Time warp factor: 80\n",
      "2023-12-13 17:38:07,289 INFO [asr_datamodule.py:268] Num frame mask: 10\n",
      "2023-12-13 17:38:07,289 INFO [asr_datamodule.py:281] About to create train dataset\n",
      "2023-12-13 17:38:07,289 INFO [asr_datamodule.py:308] Using DynamicBucketingSampler.\n",
      "2023-12-13 17:38:08,546 WARNING [train.py:996] Exclude cut with ID 3557-8342-0013-68283_sp1.1 from training. Duration: 0.836375\n",
      "2023-12-13 17:38:09,412 WARNING [train.py:996] Exclude cut with ID 7255-291500-0005-139593_sp1.1 from training. Duration: 22.7590625\n",
      "2023-12-13 17:38:10,141 WARNING [train.py:996] Exclude cut with ID 6426-64292-0017-16207 from training. Duration: 21.68\n",
      "2023-12-13 17:38:10,756 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536 from training. Duration: 23.795\n",
      "2023-12-13 17:38:10,775 WARNING [train.py:996] Exclude cut with ID 6356-271890-0060-35810_sp0.9 from training. Duration: 20.72225\n",
      "2023-12-13 17:38:10,943 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536_sp1.1 from training. Duration: 21.6318125\n",
      "2023-12-13 17:38:11,050 WARNING [train.py:996] Exclude cut with ID 774-127930-0014-104445_sp1.1 from training. Duration: 0.95\n",
      "2023-12-13 17:38:11,100 WARNING [train.py:996] Exclude cut with ID 6945-60535-0076-118436_sp0.9 from training. Duration: 20.52225\n",
      "2023-12-13 17:38:11,242 INFO [asr_datamodule.py:323] About to create train dataloader\n",
      "2023-12-13 17:38:11,242 INFO [asr_datamodule.py:451] About to get dev-clean cuts\n",
      "2023-12-13 17:38:11,243 INFO [asr_datamodule.py:458] About to get dev-other cuts\n",
      "2023-12-13 17:38:11,244 INFO [asr_datamodule.py:354] About to create dev dataset\n",
      "2023-12-13 17:38:11,455 INFO [asr_datamodule.py:371] About to create dev dataloader\n",
      "2023-12-13 17:38:11,456 INFO [train.py:1112] Sanity check -- see if any of the batches in epoch 1 would cause OOM.\n",
      "2023-12-13 17:38:12,704 WARNING [train.py:996] Exclude cut with ID 3557-8342-0013-68283_sp1.1 from training. Duration: 0.836375\n",
      "2023-12-13 17:38:13,600 WARNING [train.py:996] Exclude cut with ID 7255-291500-0005-139593_sp1.1 from training. Duration: 22.7590625\n",
      "2023-12-13 17:38:14,327 WARNING [train.py:996] Exclude cut with ID 6426-64292-0017-16207 from training. Duration: 21.68\n",
      "2023-12-13 17:38:14,949 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536 from training. Duration: 23.795\n",
      "2023-12-13 17:38:14,968 WARNING [train.py:996] Exclude cut with ID 6356-271890-0060-35810_sp0.9 from training. Duration: 20.72225\n",
      "2023-12-13 17:38:15,137 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536_sp1.1 from training. Duration: 21.6318125\n",
      "2023-12-13 17:38:15,245 WARNING [train.py:996] Exclude cut with ID 774-127930-0014-104445_sp1.1 from training. Duration: 0.95\n",
      "2023-12-13 17:38:15,296 WARNING [train.py:996] Exclude cut with ID 6945-60535-0076-118436_sp0.9 from training. Duration: 20.52225\n",
      "2023-12-13 17:38:17,153 WARNING [train.py:996] Exclude cut with ID 3557-8342-0013-68283_sp1.1 from training. Duration: 0.836375\n",
      "2023-12-13 17:38:17,532 WARNING [train.py:996] Exclude cut with ID 7255-291500-0005-139593_sp1.1 from training. Duration: 22.7590625\n",
      "2023-12-13 17:38:18,760 WARNING [train.py:996] Exclude cut with ID 6426-64292-0017-16207 from training. Duration: 21.68\n",
      "2023-12-13 17:38:19,370 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536 from training. Duration: 23.795\n",
      "2023-12-13 17:38:19,390 WARNING [train.py:996] Exclude cut with ID 6356-271890-0060-35810_sp0.9 from training. Duration: 20.72225\n",
      "2023-12-13 17:38:19,559 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536_sp1.1 from training. Duration: 21.6318125\n",
      "2023-12-13 17:38:19,666 WARNING [train.py:996] Exclude cut with ID 774-127930-0014-104445_sp1.1 from training. Duration: 0.95\n",
      "2023-12-13 17:38:19,717 WARNING [train.py:996] Exclude cut with ID 6945-60535-0076-118436_sp0.9 from training. Duration: 20.52225\n",
      "2023-12-13 17:38:22,353 WARNING [train.py:996] Exclude cut with ID 6978-92210-0019-77731_sp1.1 from training. Duration: 20.436375\n",
      "2023-12-13 17:38:22,522 WARNING [train.py:996] Exclude cut with ID 1914-133440-0031-22196 from training. Duration: 20.47\n",
      "2023-12-13 17:38:22,780 WARNING [train.py:996] Exclude cut with ID 298-126791-0067-10195_sp0.9 from training. Duration: 21.438875\n",
      "2023-12-13 17:38:23,284 WARNING [train.py:996] Exclude cut with ID 7357-94126-0009-2333 from training. Duration: 24.32\n",
      "2023-12-13 17:38:23,734 WARNING [train.py:996] Exclude cut with ID 7859-102521-0017-25559_sp1.1 from training. Duration: 22.2954375\n",
      "2023-12-13 17:38:24,096 WARNING [train.py:996] Exclude cut with ID 453-131332-0000-56609 from training. Duration: 22.8\n",
      "2023-12-13 17:38:24,786 WARNING [train.py:996] Exclude cut with ID 3488-85273-0017-128087 from training. Duration: 24.73\n",
      "2023-12-13 17:38:25,143 WARNING [train.py:996] Exclude cut with ID 1112-1043-0006-102230_sp0.9 from training. Duration: 21.8333125\n",
      "2023-12-13 17:38:25,250 WARNING [train.py:996] Exclude cut with ID 4234-40345-0022-1675 from training. Duration: 20.795\n",
      "2023-12-13 17:38:25,305 WARNING [train.py:996] Exclude cut with ID 6482-98857-0025-28936_sp0.9 from training. Duration: 20.0055625\n",
      "2023-12-13 17:38:25,845 WARNING [train.py:996] Exclude cut with ID 432-122774-0017-128166_sp1.1 from training. Duration: 20.3590625\n",
      "2023-12-13 17:38:27,836 WARNING [train.py:996] Exclude cut with ID 8291-282929-0002-53514_sp0.9 from training. Duration: 22.4666875\n",
      "2023-12-13 17:38:29,099 WARNING [train.py:996] Exclude cut with ID 1025-75365-0008-2471_sp0.9 from training. Duration: 22.0666875\n",
      "2023-12-13 17:38:29,859 WARNING [train.py:996] Exclude cut with ID 1914-133440-0024-22189 from training. Duration: 22.72\n",
      "2023-12-13 17:38:30,423 WARNING [train.py:996] Exclude cut with ID 6978-92210-0001-77713_sp0.9 from training. Duration: 22.0166875\n",
      "2023-12-13 17:38:30,822 WARNING [train.py:996] Exclude cut with ID 7357-94126-0026-2350 from training. Duration: 22.555\n",
      "2023-12-13 17:38:31,276 WARNING [train.py:996] Exclude cut with ID 3340-169293-0054-33813_sp0.9 from training. Duration: 22.6666875\n",
      "2023-12-13 17:38:31,332 WARNING [train.py:996] Exclude cut with ID 7859-102521-0017-25559_sp0.9 from training. Duration: 27.25\n",
      "2023-12-13 17:38:32,187 WARNING [train.py:996] Exclude cut with ID 3488-85273-0017-128087_sp1.1 from training. Duration: 22.4818125\n",
      "2023-12-13 17:38:32,476 WARNING [train.py:996] Exclude cut with ID 432-122774-0010-128159_sp0.9 from training. Duration: 22.22225\n",
      "2023-12-13 17:38:32,937 WARNING [train.py:996] Exclude cut with ID 4278-13270-0009-66670_sp1.1 from training. Duration: 20.82275\n",
      "2023-12-13 17:38:34,681 WARNING [train.py:996] Exclude cut with ID 6758-72288-0033-66764_sp0.9 from training. Duration: 25.988875\n",
      "2023-12-13 17:38:34,891 WARNING [train.py:996] Exclude cut with ID 2929-85685-0062-73605_sp0.9 from training. Duration: 22.511125\n",
      "2023-12-13 17:38:35,411 WARNING [train.py:996] Exclude cut with ID 5239-32139-0047-48544_sp0.9 from training. Duration: 30.1555625\n",
      "2023-12-13 17:38:35,563 WARNING [train.py:996] Exclude cut with ID 1914-133440-0024-22189_sp1.1 from training. Duration: 20.6545625\n",
      "2023-12-13 17:38:38,110 WARNING [train.py:996] Exclude cut with ID 2364-131735-0112-28660_sp0.9 from training. Duration: 20.488875\n",
      "2023-12-13 17:38:39,072 WARNING [train.py:996] Exclude cut with ID 8631-249866-0039-82374_sp0.9 from training. Duration: 20.661125\n",
      "2023-12-13 17:38:39,699 WARNING [train.py:996] Exclude cut with ID 3488-85273-0038-128108 from training. Duration: 20.34\n",
      "2023-12-13 17:38:40,330 WARNING [train.py:996] Exclude cut with ID 3699-47246-0007-22099_sp0.9 from training. Duration: 20.26675\n",
      "2023-12-13 17:38:40,485 WARNING [train.py:996] Exclude cut with ID 3488-65654-0031-128059 from training. Duration: 20.44\n",
      "2023-12-13 17:38:43,028 WARNING [train.py:996] Exclude cut with ID 8631-249866-0025-82360_sp0.9 from training. Duration: 21.7944375\n",
      "2023-12-13 17:38:43,371 WARNING [train.py:996] Exclude cut with ID 4511-76322-0006-111849_sp0.9 from training. Duration: 24.411125\n",
      "2023-12-13 17:38:48,117 WARNING [train.py:996] Exclude cut with ID 7255-291500-0005-139593_sp0.9 from training. Duration: 27.8166875\n",
      "2023-12-13 17:38:50,694 WARNING [train.py:996] Exclude cut with ID 453-131332-0000-56609_sp1.1 from training. Duration: 20.72725\n",
      "2023-12-13 17:38:50,913 WARNING [train.py:996] Exclude cut with ID 1085-156170-0017-14120 from training. Duration: 21.01\n",
      "2023-12-13 17:38:51,252 WARNING [train.py:996] Exclude cut with ID 8291-282929-0007-53519_sp0.9 from training. Duration: 28.72225\n",
      "2023-12-13 17:38:52,476 WARNING [train.py:996] Exclude cut with ID 543-133211-0007-60160_sp0.9 from training. Duration: 21.388875\n",
      "2023-12-13 17:38:53,174 WARNING [train.py:996] Exclude cut with ID 6951-79737-0043-56669 from training. Duration: 25.285\n",
      "2023-12-13 17:38:54,202 WARNING [train.py:996] Exclude cut with ID 3488-85273-0038-128108_sp0.9 from training. Duration: 22.6\n",
      "2023-12-13 17:38:55,186 WARNING [train.py:996] Exclude cut with ID 1085-156170-0017-14120_sp0.9 from training. Duration: 23.3444375\n",
      "2023-12-13 17:38:55,262 WARNING [train.py:996] Exclude cut with ID 6951-79737-0043-56669_sp0.9 from training. Duration: 28.0944375\n",
      "2023-12-13 17:38:56,789 WARNING [train.py:996] Exclude cut with ID 6951-79737-0018-56644 from training. Duration: 21.105\n",
      "2023-12-13 17:38:57,889 WARNING [train.py:996] Exclude cut with ID 5239-32139-0047-48544 from training. Duration: 27.14\n",
      "2023-12-13 17:38:58,127 WARNING [train.py:996] Exclude cut with ID 453-131332-0000-56609_sp0.9 from training. Duration: 25.3333125\n",
      "2023-12-13 17:38:58,555 WARNING [train.py:996] Exclude cut with ID 4964-30587-0040-21470_sp0.9 from training. Duration: 25.0944375\n",
      "2023-12-13 17:38:58,739 WARNING [train.py:996] Exclude cut with ID 4964-30587-0085-21515_sp0.9 from training. Duration: 20.85\n",
      "2023-12-13 17:38:58,797 WARNING [train.py:996] Exclude cut with ID 7357-94126-0045-2369 from training. Duration: 21.075\n",
      "2023-12-13 17:39:00,129 WARNING [train.py:996] Exclude cut with ID 7255-291500-0003-139591_sp1.1 from training. Duration: 24.395375\n",
      "2023-12-13 17:39:00,564 WARNING [train.py:996] Exclude cut with ID 1250-135782-0005-138257_sp0.9 from training. Duration: 21.688875\n",
      "2023-12-13 17:39:00,908 WARNING [train.py:996] Exclude cut with ID 4860-13185-0032-103840 from training. Duration: 20.77\n",
      "2023-12-13 17:39:01,770 WARNING [train.py:996] Exclude cut with ID 2195-150901-0045-1772_sp0.9 from training. Duration: 22.9444375\n",
      "2023-12-13 17:39:03,301 WARNING [train.py:996] Exclude cut with ID 432-122774-0017-128166_sp0.9 from training. Duration: 24.8833125\n",
      "2023-12-13 17:39:04,247 WARNING [train.py:996] Exclude cut with ID 6758-72288-0033-66764 from training. Duration: 23.39\n",
      "2023-12-13 17:39:04,976 WARNING [train.py:996] Exclude cut with ID 6330-62850-0007-25618 from training. Duration: 22.485\n",
      "2023-12-13 17:39:05,573 WARNING [train.py:996] Exclude cut with ID 6978-92210-0019-77731 from training. Duration: 22.48\n",
      "2023-12-13 17:39:07,569 WARNING [train.py:996] Exclude cut with ID 7255-291500-0003-139591_sp0.9 from training. Duration: 29.816625\n",
      "2023-12-13 17:39:07,930 WARNING [train.py:996] Exclude cut with ID 7357-94126-0045-2369_sp0.9 from training. Duration: 23.4166875\n",
      "2023-12-13 17:39:07,957 WARNING [train.py:996] Exclude cut with ID 7255-291500-0006-139594 from training. Duration: 21.24\n",
      "2023-12-13 17:39:09,165 WARNING [train.py:996] Exclude cut with ID 7276-92427-0014-36116_sp0.9 from training. Duration: 21.3055625\n",
      "2023-12-13 17:39:09,227 WARNING [train.py:996] Exclude cut with ID 2929-85685-0062-73605 from training. Duration: 20.26\n",
      "2023-12-13 17:39:11,416 WARNING [train.py:996] Exclude cut with ID 2411-132532-0017-30799_sp1.1 from training. Duration: 0.9681875\n",
      "2023-12-13 17:39:11,954 WARNING [train.py:996] Exclude cut with ID 3488-65654-0031-128059_sp0.9 from training. Duration: 22.711125\n",
      "2023-12-13 17:39:12,422 WARNING [train.py:996] Exclude cut with ID 7255-291500-0005-139593 from training. Duration: 25.035\n",
      "2023-12-13 17:39:12,954 WARNING [train.py:996] Exclude cut with ID 7255-291500-0009-139597_sp1.1 from training. Duration: 21.786375\n",
      "2023-12-13 17:39:12,998 WARNING [train.py:996] Exclude cut with ID 6121-9014-0076-125446 from training. Duration: 21.635\n",
      "2023-12-13 17:39:15,397 WARNING [train.py:996] Exclude cut with ID 7357-94126-0026-2350_sp1.1 from training. Duration: 20.5045625\n",
      "2023-12-13 17:39:16,071 WARNING [train.py:996] Exclude cut with ID 4964-30587-0040-21470_sp1.1 from training. Duration: 20.5318125\n",
      "2023-12-13 17:39:16,173 WARNING [train.py:996] Exclude cut with ID 7395-89880-0037-32550_sp0.9 from training. Duration: 20.67225\n",
      "2023-12-13 17:39:17,086 WARNING [train.py:996] Exclude cut with ID 6010-56788-0055-57358 from training. Duration: 20.88\n",
      "2023-12-13 17:39:18,421 WARNING [train.py:996] Exclude cut with ID 7357-94126-0009-2333_sp1.1 from training. Duration: 22.1090625\n",
      "2023-12-13 17:39:18,482 WARNING [train.py:996] Exclude cut with ID 3340-169293-0021-33780_sp0.9 from training. Duration: 21.1445\n",
      "2023-12-13 17:39:18,681 WARNING [train.py:996] Exclude cut with ID 1914-133440-0031-22196_sp0.9 from training. Duration: 22.7444375\n",
      "2023-12-13 17:39:19,771 WARNING [train.py:996] Exclude cut with ID 4133-6541-0027-102561_sp1.1 from training. Duration: 0.9681875\n",
      "2023-12-13 17:39:20,184 WARNING [train.py:996] Exclude cut with ID 7357-94126-0014-2338_sp1.1 from training. Duration: 25.3818125\n",
      "2023-12-13 17:39:20,830 WARNING [train.py:996] Exclude cut with ID 7255-291500-0009-139597_sp0.9 from training. Duration: 26.62775\n",
      "2023-12-13 17:39:21,400 WARNING [train.py:996] Exclude cut with ID 7395-89880-0045-32558_sp0.9 from training. Duration: 20.52225\n",
      "2023-12-13 17:39:22,542 WARNING [train.py:996] Exclude cut with ID 1914-133440-0024-22189_sp0.9 from training. Duration: 25.2444375\n",
      "2023-12-13 17:39:23,621 WARNING [train.py:996] Exclude cut with ID 7255-291500-0008-139596_sp1.1 from training. Duration: 20.17275\n",
      "2023-12-13 17:39:25,097 WARNING [train.py:996] Exclude cut with ID 2929-85685-0044-73587_sp0.9 from training. Duration: 24.9333125\n",
      "2023-12-13 17:39:26,432 WARNING [train.py:996] Exclude cut with ID 5652-39938-0025-26673_sp0.9 from training. Duration: 22.2055625\n",
      "2023-12-13 17:39:27,799 WARNING [train.py:996] Exclude cut with ID 8631-249866-0030-82365_sp1.1 from training. Duration: 21.5409375\n",
      "2023-12-13 17:39:28,412 WARNING [train.py:996] Exclude cut with ID 7255-291500-0003-139591 from training. Duration: 26.8349375\n",
      "2023-12-13 17:39:28,528 WARNING [train.py:996] Exclude cut with ID 8040-260924-0003-77749_sp0.9 from training. Duration: 22.07225\n",
      "2023-12-13 17:39:30,984 WARNING [train.py:996] Exclude cut with ID 6951-79737-0043-56669_sp1.1 from training. Duration: 22.986375\n",
      "2023-12-13 17:39:31,405 WARNING [train.py:996] Exclude cut with ID 6978-92210-0019-77731_sp0.9 from training. Duration: 24.97775\n",
      "2023-12-13 17:39:33,700 WARNING [train.py:996] Exclude cut with ID 7255-291500-0012-139600_sp0.9 from training. Duration: 21.9333125\n",
      "2023-12-13 17:39:34,514 WARNING [train.py:996] Exclude cut with ID 585-294811-0110-144569_sp0.9 from training. Duration: 20.8944375\n",
      "2023-12-13 17:39:35,202 WARNING [train.py:996] Exclude cut with ID 7357-94126-0024-2348_sp0.9 from training. Duration: 20.32225\n",
      "2023-12-13 17:39:35,975 WARNING [train.py:996] Exclude cut with ID 8291-282929-0023-53535_sp0.9 from training. Duration: 23.7666875\n",
      "2023-12-13 17:39:36,941 WARNING [train.py:996] Exclude cut with ID 5622-44585-0006-54034_sp0.9 from training. Duration: 28.638875\n",
      "2023-12-13 17:39:40,521 WARNING [train.py:996] Exclude cut with ID 811-130148-0001-70325_sp0.9 from training. Duration: 20.861125\n",
      "2023-12-13 17:39:42,349 WARNING [train.py:996] Exclude cut with ID 1265-135635-0050-81355_sp0.9 from training. Duration: 21.8333125\n",
      "2023-12-13 17:39:43,031 WARNING [train.py:996] Exclude cut with ID 5239-32139-0047-48544_sp1.1 from training. Duration: 24.67275\n",
      "2023-12-13 17:39:44,266 WARNING [train.py:996] Exclude cut with ID 5118-111612-0016-146751_sp0.9 from training. Duration: 20.388875\n",
      "2023-12-13 17:39:44,577 WARNING [train.py:996] Exclude cut with ID 7357-94126-0021-2345_sp0.9 from training. Duration: 27.511125\n",
      "2023-12-13 17:39:48,438 WARNING [train.py:996] Exclude cut with ID 8544-281189-0060-130470_sp0.9 from training. Duration: 20.861125\n",
      "2023-12-13 17:39:50,587 WARNING [train.py:996] Exclude cut with ID 7357-94126-0014-2338 from training. Duration: 27.92\n",
      "2023-12-13 17:39:52,822 WARNING [train.py:996] Exclude cut with ID 7255-291500-0008-139596_sp0.9 from training. Duration: 24.6555625\n",
      "2023-12-13 17:39:53,216 WARNING [train.py:996] Exclude cut with ID 1250-135782-0004-138256_sp0.9 from training. Duration: 21.17225\n",
      "2023-12-13 17:39:58,893 WARNING [train.py:996] Exclude cut with ID 6330-62851-0022-25592_sp0.9 from training. Duration: 22.3166875\n",
      "2023-12-13 17:39:59,492 WARNING [train.py:996] Exclude cut with ID 7492-105653-0055-106553_sp0.9 from training. Duration: 21.97225\n",
      "2023-12-13 17:40:02,475 WARNING [train.py:996] Exclude cut with ID 2929-85685-0060-73603_sp0.9 from training. Duration: 21.361125\n",
      "2023-12-13 17:40:02,975 WARNING [train.py:996] Exclude cut with ID 7395-89880-0031-32544 from training. Duration: 20.675\n",
      "2023-12-13 17:40:05,539 WARNING [train.py:996] Exclude cut with ID 6978-92210-0030-77742_sp0.9 from training. Duration: 22.088875\n",
      "2023-12-13 17:40:07,024 WARNING [train.py:996] Exclude cut with ID 5796-66357-0007-119540 from training. Duration: 21.46\n",
      "2023-12-13 17:40:07,155 WARNING [train.py:996] Exclude cut with ID 7357-94126-0021-2345 from training. Duration: 24.76\n",
      "2023-12-13 17:40:07,428 WARNING [train.py:996] Exclude cut with ID 543-133212-0015-60222_sp0.9 from training. Duration: 21.8166875\n",
      "2023-12-13 17:40:07,729 WARNING [train.py:996] Exclude cut with ID 8291-282929-0002-53514 from training. Duration: 20.22\n",
      "2023-12-13 17:40:08,668 WARNING [train.py:996] Exclude cut with ID 2929-85685-0044-73587 from training. Duration: 22.44\n",
      "2023-12-13 17:40:09,228 WARNING [train.py:996] Exclude cut with ID 2046-178027-0000-104818_sp0.9 from training. Duration: 20.3055625\n",
      "2023-12-13 17:40:09,302 WARNING [train.py:996] Exclude cut with ID 7357-94126-0043-2367_sp0.9 from training. Duration: 20.07225\n",
      "2023-12-13 17:40:10,132 WARNING [train.py:996] Exclude cut with ID 4511-76322-0006-111849 from training. Duration: 21.97\n",
      "2023-12-13 17:40:10,643 WARNING [train.py:996] Exclude cut with ID 6330-62850-0007-25618_sp1.1 from training. Duration: 20.4409375\n",
      "2023-12-13 17:40:10,902 WARNING [train.py:996] Exclude cut with ID 7255-291500-0008-139596 from training. Duration: 22.19\n",
      "2023-12-13 17:40:11,761 WARNING [train.py:996] Exclude cut with ID 3867-173237-0077-41427_sp0.9 from training. Duration: 22.25\n",
      "2023-12-13 17:40:12,187 WARNING [train.py:996] Exclude cut with ID 3082-165428-0081-5824_sp0.9 from training. Duration: 21.8055625\n",
      "2023-12-13 17:40:12,466 WARNING [train.py:996] Exclude cut with ID 6758-72288-0033-66764_sp1.1 from training. Duration: 21.263625\n",
      "2023-12-13 17:40:13,631 WARNING [train.py:996] Exclude cut with ID 6426-64291-0000-16162_sp0.9 from training. Duration: 20.0944375\n",
      "2023-12-13 17:40:14,333 WARNING [train.py:996] Exclude cut with ID 5172-29468-0015-106650_sp0.9 from training. Duration: 21.5055625\n",
      "2023-12-13 17:40:14,395 WARNING [train.py:996] Exclude cut with ID 4295-39940-0007-97393 from training. Duration: 21.54\n",
      "2023-12-13 17:40:16,168 WARNING [train.py:996] Exclude cut with ID 5653-46179-0060-126188_sp0.9 from training. Duration: 21.17225\n",
      "2023-12-13 17:40:17,213 WARNING [train.py:996] Exclude cut with ID 7357-94126-0014-2338_sp0.9 from training. Duration: 31.02225\n",
      "2023-12-13 17:40:18,602 WARNING [train.py:996] Exclude cut with ID 3033-130750-0096-25971_sp0.9 from training. Duration: 0.92225\n",
      "2023-12-13 17:40:19,697 WARNING [train.py:996] Exclude cut with ID 7859-102521-0017-25559 from training. Duration: 24.525\n",
      "2023-12-13 17:40:20,906 WARNING [train.py:996] Exclude cut with ID 5239-32139-0030-48527_sp0.9 from training. Duration: 21.3444375\n",
      "2023-12-13 17:40:21,604 WARNING [train.py:996] Exclude cut with ID 7255-291500-0009-139597 from training. Duration: 23.965\n",
      "2023-12-13 17:40:21,908 WARNING [train.py:996] Exclude cut with ID 6709-74022-0004-118808_sp1.1 from training. Duration: 0.9409375\n",
      "2023-12-13 17:40:23,041 WARNING [train.py:996] Exclude cut with ID 3972-170212-0014-52617_sp0.9 from training. Duration: 29.1166875\n",
      "2023-12-13 17:40:25,311 WARNING [train.py:996] Exclude cut with ID 4295-39940-0007-97393_sp0.9 from training. Duration: 23.9333125\n",
      "2023-12-13 17:40:25,369 WARNING [train.py:996] Exclude cut with ID 6010-56788-0055-57358_sp0.9 from training. Duration: 23.2\n",
      "2023-12-13 17:40:25,377 WARNING [train.py:996] Exclude cut with ID 7357-94126-0021-2345_sp1.1 from training. Duration: 22.5090625\n",
      "2023-12-13 17:40:25,651 WARNING [train.py:996] Exclude cut with ID 8291-282929-0023-53535 from training. Duration: 21.39\n",
      "2023-12-13 17:40:26,241 WARNING [train.py:996] Exclude cut with ID 6330-62851-0022-25592 from training. Duration: 20.085\n",
      "2023-12-13 17:40:26,646 WARNING [train.py:996] Exclude cut with ID 7255-291500-0006-139594_sp0.9 from training. Duration: 23.6\n",
      "2023-12-13 17:40:26,904 WARNING [train.py:996] Exclude cut with ID 7699-105389-0045-5550_sp0.9 from training. Duration: 20.3055625\n",
      "2023-12-13 17:40:27,037 WARNING [train.py:996] Exclude cut with ID 7699-105389-0021-5526_sp0.9 from training. Duration: 21.2444375\n",
      "2023-12-13 17:40:29,236 WARNING [train.py:996] Exclude cut with ID 3557-8342-0013-68283 from training. Duration: 0.92\n",
      "2023-12-13 17:40:31,308 WARNING [train.py:996] Exclude cut with ID 7357-94126-0009-2333_sp0.9 from training. Duration: 27.02225\n",
      "2023-12-13 17:40:32,039 WARNING [train.py:996] Exclude cut with ID 7255-291500-0001-139589_sp0.9 from training. Duration: 20.67225\n",
      "2023-12-13 17:40:32,621 WARNING [train.py:996] Exclude cut with ID 2929-85685-0079-73622_sp1.1 from training. Duration: 27.0318125\n",
      "2023-12-13 17:40:33,412 WARNING [train.py:996] Exclude cut with ID 4957-30119-0041-5048_sp0.9 from training. Duration: 20.22775\n",
      "2023-12-13 17:40:34,535 WARNING [train.py:996] Exclude cut with ID 3867-173237-0077-41427 from training. Duration: 20.025\n",
      "2023-12-13 17:40:35,168 WARNING [train.py:996] Exclude cut with ID 6533-399-0029-128532_sp0.9 from training. Duration: 22.1055625\n",
      "2023-12-13 17:40:37,314 WARNING [train.py:996] Exclude cut with ID 8291-276745-0093-53641_sp0.9 from training. Duration: 21.061125\n",
      "2023-12-13 17:40:37,610 WARNING [train.py:996] Exclude cut with ID 3033-130750-0096-25971_sp1.1 from training. Duration: 0.7545625\n",
      "2023-12-13 17:40:37,842 WARNING [train.py:996] Exclude cut with ID 497-129325-0061-9581_sp1.1 from training. Duration: 0.97725\n",
      "2023-12-13 17:40:38,341 WARNING [train.py:996] Exclude cut with ID 8631-249866-0030-82365 from training. Duration: 23.695\n",
      "2023-12-13 17:40:39,032 WARNING [train.py:996] Exclude cut with ID 8631-249866-0030-82365_sp0.9 from training. Duration: 26.32775\n",
      "2023-12-13 17:40:40,016 WARNING [train.py:996] Exclude cut with ID 3340-169293-0054-33813 from training. Duration: 20.4\n",
      "2023-12-13 17:40:40,096 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536_sp0.9 from training. Duration: 26.438875\n",
      "2023-12-13 17:40:40,526 WARNING [train.py:996] Exclude cut with ID 7699-105389-0094-5599 from training. Duration: 23.955\n",
      "2023-12-13 17:40:41,040 WARNING [train.py:996] Exclude cut with ID 2929-85685-0079-73622_sp0.9 from training. Duration: 33.038875\n",
      "2023-12-13 17:40:41,213 WARNING [train.py:996] Exclude cut with ID 4278-13270-0007-66668 from training. Duration: 21.6300625\n",
      "2023-12-13 17:40:41,275 WARNING [train.py:996] Exclude cut with ID 7205-50138-0008-86187_sp0.9 from training. Duration: 20.7\n",
      "2023-12-13 17:40:41,780 WARNING [train.py:996] Exclude cut with ID 2195-150901-0045-1772 from training. Duration: 20.65\n",
      "2023-12-13 17:40:44,103 WARNING [train.py:996] Exclude cut with ID 3488-85273-0017-128087_sp0.9 from training. Duration: 27.47775\n",
      "2023-12-13 17:40:45,126 WARNING [train.py:996] Exclude cut with ID 7699-105389-0094-5599_sp1.1 from training. Duration: 21.77725\n",
      "2023-12-13 17:40:45,354 WARNING [train.py:996] Exclude cut with ID 2929-85685-0071-73614 from training. Duration: 20.025\n",
      "2023-12-13 17:40:45,614 WARNING [train.py:996] Exclude cut with ID 2929-85685-0071-73614_sp0.9 from training. Duration: 22.25\n",
      "2023-12-13 17:40:45,886 WARNING [train.py:996] Exclude cut with ID 8291-282929-0007-53519 from training. Duration: 25.85\n",
      "2023-12-13 17:40:46,088 WARNING [train.py:996] Exclude cut with ID 6121-9014-0076-125446_sp0.9 from training. Duration: 24.038875\n",
      "2023-12-13 17:40:46,133 WARNING [train.py:996] Exclude cut with ID 4278-13270-0007-66668_sp0.9 from training. Duration: 24.033375\n",
      "2023-12-13 17:40:46,303 WARNING [train.py:996] Exclude cut with ID 4964-30587-0040-21470 from training. Duration: 22.585\n",
      "2023-12-13 17:40:47,627 WARNING [train.py:996] Exclude cut with ID 3972-170212-0014-52617 from training. Duration: 26.205\n",
      "2023-12-13 17:40:48,412 WARNING [train.py:996] Exclude cut with ID 7357-94126-0026-2350_sp0.9 from training. Duration: 25.061125\n",
      "2023-12-13 17:40:48,934 WARNING [train.py:996] Exclude cut with ID 2929-85685-0079-73622 from training. Duration: 29.735\n",
      "2023-12-13 17:40:50,180 WARNING [train.py:996] Exclude cut with ID 4278-13270-0009-66670 from training. Duration: 22.905\n",
      "2023-12-13 17:40:50,217 WARNING [train.py:996] Exclude cut with ID 5622-44585-0006-54034_sp1.1 from training. Duration: 23.4318125\n",
      "2023-12-13 17:40:51,279 WARNING [train.py:996] Exclude cut with ID 7395-89880-0047-32560_sp0.9 from training. Duration: 21.97775\n",
      "2023-12-13 17:40:51,952 WARNING [train.py:996] Exclude cut with ID 8291-282929-0007-53519_sp1.1 from training. Duration: 23.5\n",
      "2023-12-13 17:40:53,143 WARNING [train.py:996] Exclude cut with ID 5622-44585-0006-54034 from training. Duration: 25.775\n",
      "2023-12-13 17:40:53,213 WARNING [train.py:996] Exclude cut with ID 4860-13185-0032-103840_sp0.9 from training. Duration: 23.07775\n",
      "2023-12-13 17:40:53,505 WARNING [train.py:996] Exclude cut with ID 6330-62850-0007-25618_sp0.9 from training. Duration: 24.9833125\n",
      "2023-12-13 17:40:54,587 WARNING [train.py:996] Exclude cut with ID 6426-64292-0017-16207_sp0.9 from training. Duration: 24.088875\n",
      "2023-12-13 17:40:55,162 WARNING [train.py:996] Exclude cut with ID 4278-13270-0009-66670_sp0.9 from training. Duration: 25.45\n",
      "2023-12-13 17:40:55,734 WARNING [train.py:996] Exclude cut with ID 4757-1811-0023-77550_sp0.9 from training. Duration: 21.37775\n",
      "2023-12-13 17:40:57,736 WARNING [train.py:996] Exclude cut with ID 5796-66357-0007-119540_sp0.9 from training. Duration: 23.8444375\n",
      "2023-12-13 17:40:58,374 WARNING [train.py:996] Exclude cut with ID 8565-290391-0049-180_sp0.9 from training. Duration: 21.3166875\n",
      "2023-12-13 17:40:58,905 WARNING [train.py:996] Exclude cut with ID 6951-79737-0018-56644_sp0.9 from training. Duration: 23.45\n",
      "2023-12-13 17:41:00,435 WARNING [train.py:996] Exclude cut with ID 2929-85685-0044-73587_sp1.1 from training. Duration: 20.4\n",
      "2023-12-13 17:41:02,079 WARNING [train.py:996] Exclude cut with ID 4234-40345-0022-1675_sp0.9 from training. Duration: 23.1055625\n",
      "2023-12-13 17:41:02,218 WARNING [train.py:996] Exclude cut with ID 7395-89880-0031-32544_sp0.9 from training. Duration: 22.97225\n",
      "2023-12-13 17:41:02,965 WARNING [train.py:996] Exclude cut with ID 7699-105389-0094-5599_sp0.9 from training. Duration: 26.6166875\n",
      "2023-12-13 17:41:03,266 WARNING [train.py:996] Exclude cut with ID 6533-399-0047-128550_sp0.9 from training. Duration: 23.9055625\n",
      "2023-12-13 17:41:05,566 WARNING [train.py:996] Exclude cut with ID 3033-130750-0096-25971 from training. Duration: 0.83\n",
      "2023-12-13 17:41:06,657 WARNING [train.py:996] Exclude cut with ID 6533-399-0047-128550 from training. Duration: 21.515\n",
      "2023-12-13 17:41:06,669 WARNING [train.py:996] Exclude cut with ID 3972-170212-0014-52617_sp1.1 from training. Duration: 23.82275\n",
      "2023-12-13 17:41:08,855 WARNING [train.py:996] Exclude cut with ID 432-122774-0017-128166 from training. Duration: 22.395\n",
      "2023-12-13 17:41:08,992 WARNING [train.py:996] Exclude cut with ID 6951-79737-0037-56663_sp0.9 from training. Duration: 22.05\n",
      "2023-12-13 17:41:19,173 WARNING [train.py:996] Exclude cut with ID 3557-8342-0013-68283_sp1.1 from training. Duration: 0.836375\n",
      "2023-12-13 17:41:19,580 WARNING [train.py:996] Exclude cut with ID 7255-291500-0005-139593_sp1.1 from training. Duration: 22.7590625\n",
      "2023-12-13 17:41:20,350 WARNING [train.py:996] Exclude cut with ID 6426-64292-0017-16207 from training. Duration: 21.68\n",
      "2023-12-13 17:41:21,658 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536 from training. Duration: 23.795\n",
      "2023-12-13 17:41:21,678 WARNING [train.py:996] Exclude cut with ID 6356-271890-0060-35810_sp0.9 from training. Duration: 20.72225\n",
      "2023-12-13 17:41:21,854 WARNING [train.py:996] Exclude cut with ID 8291-282929-0024-53536_sp1.1 from training. Duration: 21.6318125\n",
      "2023-12-13 17:41:21,967 WARNING [train.py:996] Exclude cut with ID 774-127930-0014-104445_sp1.1 from training. Duration: 0.95\n",
      "2023-12-13 17:41:22,020 WARNING [train.py:996] Exclude cut with ID 6945-60535-0076-118436_sp0.9 from training. Duration: 20.52225\n",
      "2023-12-13 17:41:22,511 INFO [train.py:850] Epoch 1, batch 0, loss[loss=1.138, simple_loss=2.275, pruned_loss=6.331, over 864.00 frames. utt_duration=1729 frames, utt_pad_proportion=0.001732, over 2.00 utterances.], tot_loss[loss=1.138, simple_loss=2.275, pruned_loss=6.331, over 864.00 frames. utt_duration=1729 frames, utt_pad_proportion=0.001732, over 2.00 utterances.], batch size: 2, lr: 3.00e-03\n",
      "2023-12-13 17:41:36,883 INFO [train.py:850] Epoch 1, batch 50, loss[loss=0.6436, simple_loss=1.287, pruned_loss=7.393, over 1130.00 frames. utt_duration=1509 frames, utt_pad_proportion=0.00418, over 3.00 utterances.], tot_loss[loss=0.6439, simple_loss=1.288, pruned_loss=7.118, over 46980.98 frames. utt_duration=1379 frames, utt_pad_proportion=0.00948, over 136.42 utterances.], batch size: 3, lr: 3.00e-03\n",
      "2023-12-13 17:41:51,881 INFO [train.py:850] Epoch 1, batch 100, loss[loss=0.3932, simple_loss=0.7864, pruned_loss=6.927, over 872.00 frames. utt_duration=1747 frames, utt_pad_proportion=0.004558, over 2.00 utterances.], tot_loss[loss=0.5878, simple_loss=1.176, pruned_loss=7.082, over 82640.80 frames. utt_duration=1310 frames, utt_pad_proportion=0.03261, over 252.53 utterances.], batch size: 2, lr: 3.00e-03\n",
      "2023-12-13 17:42:06,315 INFO [train.py:850] Epoch 1, batch 150, loss[loss=0.4432, simple_loss=0.8864, pruned_loss=6.861, over 871.00 frames. utt_duration=1742 frames, utt_pad_proportion=0.0008601, over 2.00 utterances.], tot_loss[loss=0.5587, simple_loss=1.117, pruned_loss=7.103, over 111082.69 frames. utt_duration=1298 frames, utt_pad_proportion=0.02773, over 342.63 utterances.], batch size: 2, lr: 3.00e-03\n",
      "2023-12-13 17:42:21,054 INFO [train.py:850] Epoch 1, batch 200, loss[loss=0.5312, simple_loss=1.062, pruned_loss=7.058, over 1157.00 frames. utt_duration=1158 frames, utt_pad_proportion=0.009829, over 4.00 utterances.], tot_loss[loss=0.5404, simple_loss=1.081, pruned_loss=7.091, over 133168.86 frames. utt_duration=1319 frames, utt_pad_proportion=0.02665, over 404.24 utterances.], batch size: 4, lr: 3.00e-03\n",
      "2023-12-13 17:42:35,583 INFO [train.py:850] Epoch 1, batch 250, loss[loss=0.4212, simple_loss=0.8424, pruned_loss=7.021, over 1046.00 frames. utt_duration=1397 frames, utt_pad_proportion=0.003566, over 3.00 utterances.], tot_loss[loss=0.5217, simple_loss=1.043, pruned_loss=7.089, over 149997.41 frames. utt_duration=1252 frames, utt_pad_proportion=0.0406, over 479.62 utterances.], batch size: 3, lr: 3.00e-03\n",
      "2023-12-13 17:42:50,228 INFO [train.py:850] Epoch 1, batch 300, loss[loss=0.4914, simple_loss=0.9829, pruned_loss=6.716, over 1185.00 frames. utt_duration=1186 frames, utt_pad_proportion=0.007119, over 4.00 utterances.], tot_loss[loss=0.5066, simple_loss=1.013, pruned_loss=7.042, over 163493.95 frames. utt_duration=1261 frames, utt_pad_proportion=0.03545, over 519.15 utterances.], batch size: 4, lr: 3.00e-03\n",
      "2023-12-13 17:43:04,621 INFO [train.py:850] Epoch 1, batch 350, loss[loss=0.4011, simple_loss=0.8021, pruned_loss=7.082, over 1151.00 frames. utt_duration=1536 frames, utt_pad_proportion=0.001733, over 3.00 utterances.], tot_loss[loss=0.4969, simple_loss=0.9937, pruned_loss=7.03, over 173716.13 frames. utt_duration=1268 frames, utt_pad_proportion=0.0352, over 548.76 utterances.], batch size: 3, lr: 3.00e-03\n",
      "2023-12-13 17:43:19,393 INFO [train.py:850] Epoch 1, batch 400, loss[loss=0.4243, simple_loss=0.8487, pruned_loss=7.066, over 1061.00 frames. utt_duration=1416 frames, utt_pad_proportion=0.003052, over 3.00 utterances.], tot_loss[loss=0.4865, simple_loss=0.973, pruned_loss=7.003, over 182146.92 frames. utt_duration=1256 frames, utt_pad_proportion=0.03837, over 580.99 utterances.], batch size: 3, lr: 3.00e-03\n",
      "2023-12-13 17:43:33,761 INFO [train.py:850] Epoch 1, batch 450, loss[loss=0.5793, simple_loss=1.159, pruned_loss=7.365, over 1064.00 frames. utt_duration=1419 frames, utt_pad_proportion=0.001173, over 3.00 utterances.], tot_loss[loss=0.48, simple_loss=0.9599, pruned_loss=6.994, over 187444.64 frames. utt_duration=1217 frames, utt_pad_proportion=0.04937, over 616.76 utterances.], batch size: 3, lr: 2.99e-03\n",
      "2023-12-13 17:43:48,265 INFO [train.py:850] Epoch 1, batch 500, loss[loss=0.4546, simple_loss=0.9093, pruned_loss=6.911, over 979.00 frames. utt_duration=1307 frames, utt_pad_proportion=0.00229, over 3.00 utterances.], tot_loss[loss=0.4703, simple_loss=0.9406, pruned_loss=6.977, over 191686.60 frames. utt_duration=1235 frames, utt_pad_proportion=0.04487, over 621.78 utterances.], batch size: 3, lr: 2.99e-03\n",
      "2023-12-13 17:44:02,545 INFO [train.py:850] Epoch 1, batch 550, loss[loss=0.4864, simple_loss=0.9728, pruned_loss=7.037, over 995.00 frames. utt_duration=1328 frames, utt_pad_proportion=0.003003, over 3.00 utterances.], tot_loss[loss=0.4704, simple_loss=0.9408, pruned_loss=6.975, over 195388.28 frames. utt_duration=1230 frames, utt_pad_proportion=0.0422, over 636.26 utterances.], batch size: 3, lr: 2.99e-03\n",
      "2023-12-13 17:44:17,298 INFO [train.py:850] Epoch 1, batch 600, loss[loss=0.379, simple_loss=0.7581, pruned_loss=6.943, over 1009.00 frames. utt_duration=1348 frames, utt_pad_proportion=0.001728, over 3.00 utterances.], tot_loss[loss=0.4645, simple_loss=0.929, pruned_loss=6.974, over 199524.74 frames. utt_duration=1235 frames, utt_pad_proportion=0.03961, over 647.09 utterances.], batch size: 3, lr: 2.99e-03\n",
      "2023-12-13 17:44:31,701 INFO [train.py:850] Epoch 1, batch 650, loss[loss=0.399, simple_loss=0.798, pruned_loss=6.864, over 876.00 frames. utt_duration=1752 frames, utt_pad_proportion=0.008767, over 2.00 utterances.], tot_loss[loss=0.4583, simple_loss=0.9165, pruned_loss=6.949, over 202412.05 frames. utt_duration=1244 frames, utt_pad_proportion=0.03785, over 651.47 utterances.], batch size: 2, lr: 2.99e-03\n",
      "2023-12-13 17:44:46,176 INFO [train.py:850] Epoch 1, batch 700, loss[loss=0.4125, simple_loss=0.8251, pruned_loss=6.782, over 941.00 frames. utt_duration=1256 frames, utt_pad_proportion=0.006593, over 3.00 utterances.], tot_loss[loss=0.455, simple_loss=0.91, pruned_loss=6.975, over 203379.62 frames. utt_duration=1256 frames, utt_pad_proportion=0.03604, over 648.75 utterances.], batch size: 3, lr: 2.99e-03\n",
      "2023-12-13 17:45:00,692 INFO [train.py:850] Epoch 1, batch 750, loss[loss=0.3896, simple_loss=0.7792, pruned_loss=6.915, over 860.00 frames. utt_duration=1723 frames, utt_pad_proportion=0.002316, over 2.00 utterances.], tot_loss[loss=0.4501, simple_loss=0.9002, pruned_loss=6.967, over 205290.66 frames. utt_duration=1270 frames, utt_pad_proportion=0.03426, over 647.29 utterances.], batch size: 2, lr: 2.98e-03\n",
      "2023-12-13 17:45:15,083 INFO [train.py:850] Epoch 1, batch 800, loss[loss=0.4637, simple_loss=0.9273, pruned_loss=7.135, over 1016.00 frames. utt_duration=1356 frames, utt_pad_proportion=0.003674, over 3.00 utterances.], tot_loss[loss=0.4494, simple_loss=0.8989, pruned_loss=6.955, over 205219.46 frames. utt_duration=1258 frames, utt_pad_proportion=0.03648, over 653.08 utterances.], batch size: 3, lr: 2.98e-03\n",
      "2023-12-13 17:45:29,716 INFO [train.py:850] Epoch 1, batch 850, loss[loss=0.4622, simple_loss=0.9244, pruned_loss=7.101, over 1032.00 frames. utt_duration=1378 frames, utt_pad_proportion=0.0007252, over 3.00 utterances.], tot_loss[loss=0.4459, simple_loss=0.8918, pruned_loss=6.932, over 207599.72 frames. utt_duration=1261 frames, utt_pad_proportion=0.036, over 659.54 utterances.], batch size: 3, lr: 2.98e-03\n",
      "2023-12-13 17:45:44,414 INFO [train.py:850] Epoch 1, batch 900, loss[loss=0.4168, simple_loss=0.8336, pruned_loss=6.858, over 1048.00 frames. utt_duration=1397 frames, utt_pad_proportion=0.004748, over 3.00 utterances.], tot_loss[loss=0.4426, simple_loss=0.8852, pruned_loss=6.926, over 208326.14 frames. utt_duration=1272 frames, utt_pad_proportion=0.03549, over 656.08 utterances.], batch size: 3, lr: 2.98e-03\n",
      "2023-12-13 17:45:58,647 INFO [train.py:850] Epoch 1, batch 950, loss[loss=0.3121, simple_loss=0.6241, pruned_loss=6.487, over 873.00 frames. utt_duration=1748 frames, utt_pad_proportion=0.003136, over 2.00 utterances.], tot_loss[loss=0.4416, simple_loss=0.8831, pruned_loss=6.921, over 207373.71 frames. utt_duration=1235 frames, utt_pad_proportion=0.0459, over 672.42 utterances.], batch size: 2, lr: 2.97e-03\n",
      "2023-12-13 17:46:13,333 INFO [train.py:850] Epoch 1, batch 1000, loss[loss=0.4135, simple_loss=0.8269, pruned_loss=6.621, over 872.00 frames. utt_duration=1746 frames, utt_pad_proportion=0.004561, over 2.00 utterances.], tot_loss[loss=0.4417, simple_loss=0.8833, pruned_loss=6.935, over 207589.75 frames. utt_duration=1221 frames, utt_pad_proportion=0.04979, over 680.96 utterances.], batch size: 2, lr: 2.97e-03\n",
      "2023-12-13 17:46:27,735 INFO [train.py:850] Epoch 1, batch 1050, loss[loss=0.3685, simple_loss=0.7371, pruned_loss=6.724, over 878.00 frames. utt_duration=1757 frames, utt_pad_proportion=0.008465, over 2.00 utterances.], tot_loss[loss=0.4422, simple_loss=0.8844, pruned_loss=6.942, over 208230.41 frames. utt_duration=1215 frames, utt_pad_proportion=0.04667, over 686.12 utterances.], batch size: 2, lr: 2.97e-03\n",
      "2023-12-13 17:46:42,515 INFO [train.py:850] Epoch 1, batch 1100, loss[loss=0.5355, simple_loss=1.071, pruned_loss=7.34, over 977.00 frames. utt_duration=1305 frames, utt_pad_proportion=0.004831, over 3.00 utterances.], tot_loss[loss=0.4426, simple_loss=0.8853, pruned_loss=6.95, over 209550.89 frames. utt_duration=1219 frames, utt_pad_proportion=0.04698, over 688.20 utterances.], batch size: 3, lr: 2.96e-03\n",
      "2023-12-13 17:46:57,002 INFO [train.py:850] Epoch 1, batch 1150, loss[loss=0.4481, simple_loss=0.8961, pruned_loss=6.81, over 1075.00 frames. utt_duration=861 frames, utt_pad_proportion=0.04227, over 5.00 utterances.], tot_loss[loss=0.4411, simple_loss=0.8822, pruned_loss=6.957, over 210005.11 frames. utt_duration=1215 frames, utt_pad_proportion=0.04785, over 692.04 utterances.], batch size: 5, lr: 2.96e-03\n"
     ]
    }
   ],
   "source": [
    "!cd /home/jupyter/storage2/working_area_silvana2/icefall/egs/librispeech/ASR && export CUDA_VISIBLE_DEVICES=\"0\" && ./pruned_transducer_stateless4/train.py --world-size 1 --num-epochs 9 --max-duration 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c48d7-2bf7-433a-bbd0-efd1ea211896",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd pruned_transducer_stateless4/exp/tensorboard && tensorboard dev upload --logdir . --description \"pruned transducer training for LibriSpeech with icefall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70717565-6ca4-4271-aecc-e7477efee87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jupyter/storage2/working_area_silvana2/icefall/egs/librispeech/ASR/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c8d07-7b1a-4f64-b524-f0268c57a0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
